{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labor 06 - Neurális hálózatok alapjai\n",
    "\n",
    "## Kézzel írott számjegyek II.\n",
    "\n",
    "A következő gyakorlat során áttérünk a neurális hálózatok használatára. Pálda feladatnak a kézzel írt számok (0-9) felismerését fogjuk alkalmazni, amit az előző (L05) labor során is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurális hálózatok bevezetése\n",
    "\n",
    "Az eddigi laborok során megismerhettük a tanuló algoritmusok alapjait. A módszerünket bővítettük több változós esetre illetve regressziós és klasszifikációs problémákra is adtunk megoldást. \n",
    "\n",
    "Eddigi modellünket üssze foglalhatjuk az alábbi ábra szerint:\n",
    "\n",
    "<img src=\"files/Pics/L06_Neuron_01.png\" width=450>\n",
    "\n",
    ",ahol <br>\n",
    "$x_{n}$-ek jelölik a bemeneteket, $x_{0} = 1$ a BIAS tag <br>\n",
    "$w_{n}$-ek jelölik a súlyokat <br>\n",
    "$s$ a szummázott összeget, mely a súlyok és bemenetek szorzatait tartalmazza <br>\n",
    "$a$ jelöli az aktivációs függvény (szigmoid függvény például) <br>\n",
    "$y$ jelöli a kimentet <br>\n",
    "\n",
    "Jobban megnézve ezt az ábrát ténylegesen hasonlít egy biológiai neuronra. \n",
    "<img src=\"files/Pics/L06_Neuron_02.png\" width=450>\n",
    "\n",
    "Vezessük be tehát a fenti modellt, mint neuron vagyis Perceptron modellt.\n",
    "\n",
    "A neuronok pedig több rétegű hálózatba rendezhetők. Ezt a hálózatot nevezzük neurális hálózatnak vagy MLP-nek (Multi Layer Perceptron).\n",
    "\n",
    "#### MLP felépítése és működése\n",
    "\n",
    "Vegyük az alábbi architektúrát:\n",
    "\n",
    "<img src=\"files/Pics/L06_NeuralNet.png\" width=350>\n",
    "\n",
    "A vázolt eset egy bemeneti rétegből, egy rejtett rétegből és egy kimeneti rétegből. A bemeneti réteg 2 neuront tartalmaz BIAS nálkül, a rejtett réteg 3 neuront tartalmaz BIAS nélkül és a kimeneti réteg 1 neuronból áll. BIAS tagok a modellben rétegenként adhatók hozzá és egy megfelelő súllyal kapcsolódnak a következő reteg elemihez. \n",
    "\n",
    "Teljesen kapcsolt vagy Fully Connected hálóról beszélhetünk, ha minden neuron összeköttetésben áll a következő réteg összes neuronjával. Szigmoid aktivációs függvényt feltételezve, BIAS tagok nélkül tekintsük át a predikció lépéseit (Forward Step) és a szükséges mátrixok és vektorok dimenzióit. A súlyokat ismertnek tekintjük.\n",
    "\n",
    "$ \\underset{1\\times 2}{\\mathrm{x}} \\times \\underset{2\\times 3}{\\mathrm{w^{(1)}}} = \\underset{1\\times 3}{\\mathrm{s^{(2)}}} $\n",
    "\n",
    "$ \\underset{1\\times 3}{\\mathrm{a^{(2)}}} = f(\\underset{1\\times 3}{\\mathrm{s^{(2)}}}) = sigmoid(\\underset{1\\times 3}{\\mathrm{s^{(2)}}}) $ \n",
    "\n",
    "$ \\underset{1\\times 1}{\\mathrm{s^{(3)}}} = \\underset{1\\times 3}{\\mathrm{a^{(2)}}} \\times \\underset{3\\times 1}{\\mathrm{w^{(2)}}} $\n",
    "\n",
    "$ \\underset{1\\times 1}{\\mathrm{\\hat{y}}} = f(\\underset{1\\times 1}{\\mathrm{s^{(3)}}}) = sigmoid(\\underset{1\\times 1}{\\mathrm{s^{(3)}}}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Példánkon keresztül nézzük meg, hogy működik ez a gyakorlatban."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Szükséges csomagok beimportálása adatok beolvasása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"Lab6data.mat\")                          # adatok beolvasása\n",
    "X = data[\"X\"]\n",
    "Y = data [\"y\"]\n",
    "m = X.shape[0]                                          # adatok elrendezése\n",
    "del data\n",
    "print('''Shape of the dataset in order X and Y:\n",
    "''',X.shape,'\\n',Y.shape,'\\n')\n",
    "\n",
    "data = loadmat(\"Lab6weights.mat\")                       # előre optimalizált súlyok beolvasása\n",
    "w1 = data[\"Theta1\"]\n",
    "w2 = data[\"Theta2\"]                                     # súlyok elrendezése\n",
    "del data\n",
    "print('''Shape of the weights in order 1 and 2:\n",
    "''',w1.shape,'\\n',w2.shape,'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A beolvasott adataok dimenzióinak megvizsgálása után láthatjuk, hogy 5000 bemeneti minták van. 400 bemeneti paraméterünk, ami a 20x20 képek pixel számának felel meg. Az első súlymátrixunk 401 oszlopot tartalmaz, ami jelzi, hogy a bementi adatokat a BIAS taggal kiegészítették. A rejtett rétegben 25 neuron van, erre utal az első súlymátrix első dimenziója. A második súlymátrix dimenzióiból látszik, hogy 10 kimeneti neuron szerepel a modellben a 10 számjegynek megfelelően és BIASal kiegészítve 26 bementi értéke van.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Adat vizualizáció\n",
    "\n",
    "Az adatok vizualizációjához véletlen szerűen kiveszünk 100 mintát, vissza alakítjuk eredeti alakjukra és kirajzoltatjuk őket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Printing some random data ...\")\n",
    "fig, ax = plt.subplots(10,10, figsize =(8,8))               # egy plotra több alplot = subplots (10x10 darab)\n",
    "for i in range(10):\n",
    "    for j in range(10):                                     # random adat mind a 100 helyre\n",
    "        ax[i,j].imshow(X[np.random.randint(0,m+1),:].reshape(20,20, order = \"F\"), cmap=\"hot\")\n",
    "        ax[i,j].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Predikció és Pontosság\n",
    "\n",
    "Az elméleti bevezető alapján implementáljuk a predikciós lépést (Forward Step). Figyeljünk a BIAS tagok hozzá adására és megfelelő mátrix dimenziókra. Mivel klasszifikációs problémáról beszélünk a kiszámított valószínűségek közül itt is ki kell választanunk a megfelelő osztályt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):                                                  # szigmoig függvény definíciója\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def predict(X,w1,w2):                                            # predikciós függvény definíciója\n",
    "##########################################################\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "    return pred                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próbáljuk ki a megírt predikciós függvényt. Véletlen szerűen kiválasztunk egy elemet és elvégezzük rajta a predict() függvényt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "i= random.randint(1,m+1)\n",
    "\n",
    "X_ex = X[i,:].reshape(1,-1)       # megfelelő mátrix dimenziók és formátum miatt kell a reshape()\n",
    "pred_ex = predict(X_ex,w1,w2)\n",
    "\n",
    "print('Showing You a %.0f'% Y[i], '\\nThe prediction was %.0f' % pred_ex)\n",
    "fig = plt.figure(figsize=(2,2))\n",
    "plt.imshow(X[i,:].reshape(20,20).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elvégezve a predikciót az összes elemre és össze hasonlítva az eredeti címkékkel megkaphatjuk, hogy milyen jól tanulta be a minta adatokat az algoritmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,Y):                                            # pontosság függvény definíciója\n",
    "    return (np.sum(pred[:,np.newaxis]==Y)/5000)*100              # predikció vektora megegyezik az Y-al / mintaszám * 100%\n",
    "\n",
    "\n",
    "pred = predict(X,w1,w2)\n",
    "print('\\nTraining set Accuracy: ', accuracy(pred,Y), ' %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
