{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/Pics/LOGOS.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labor 05: Többosztályos klasszifikáció - Egy vs Többi (One vs All)\n",
    "\n",
    "### Kézzel írott számjegyek\n",
    "\n",
    "Ebben a feladatban logisztikus regressziót fogunk alkalmazni, hogy elkülönítsünk kézzel írt számjegyeket (0 és 9 között). Ez a feladat manapság elterjedt a postai irányítószám leolvasásától kezdve a banki számlákon beírt számok felismeréséig és tovább."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: importáljuk be a megfelelő csomagokat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Adatok beolvasása és vizualizálása\n",
    "\n",
    "A Lab5data.mat fájl tartalmazza az adatainkat. A fájl 5000 darab 20x20 pixeles mintaképet tartalmaz. A mátrixban egy minta egy sornak felel meg, melyhez a képeket kiterítettük. A kiterítésre példa alább.\n",
    "\n",
    "<img src=\"files/Pics/L05_Flatten.png\" width=450>\n",
    "\n",
    "Ennek megfelelően az adatokat beolvasva egy 5000x400-as bemeneti mátrixot fogunk kapni és egy 5000x1-es mátrixot, amik a címkéket tartalmazzák.\n",
    "\n",
    "A megjelenítéshez pedig értelem szerűen ennek megfelelően kell a képeket vissza alakítanunk. A későbbiek során az algoritmusunknak minden pixel egy bemeneti változónak fog számítani, és minden pixel értéke egy 0-2 közé normalizált szürke árnyalatos érték. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat(\"Lab5data.mat\")                                       # .mat file beolvasása\n",
    "X = mat[\"X\"]                                                        # X rendezése\n",
    "Y = mat[\"y\"]                                                        # Y rebbdezése\n",
    "m = X.shape[0]                                                      # adatok\n",
    "\n",
    "print('''Shape of the dataset in order X and Y:\n",
    "''',X.shape,'\\n',Y.shape,'\\n')\n",
    "\n",
    "print(\"Now showing some random data from the dataset ...\")          # kirajzoltatunk néhány random elemet\n",
    "fig, axis = plt.subplots(10,10,figsize = (8,8))                     # mivel egy plotra akarunk több ábrát -> subplots\n",
    "for i in range(10):                                                 # 10 x 10 kis ábrát akarunk\n",
    "    for j in range(10):\n",
    "        axis[i,j].imshow(X[np.random.randint(0,m+1),:].reshape(20,20,order=\"F\"),cmap=\"hot\")   # random beolvasás\n",
    "        axis[i,j].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Költségfüggvény és Gradient Descent\n",
    "\n",
    "Emlékeztető: <br>\n",
    "A korábbi gyakorlatok során bevezettük az alábbi költség függvényt, mely 2 osztály elkülönítésére volt alkalmas. $y=0\\ és\\ y=1$ eseteket különböztettünk csak meg.\n",
    "\n",
    "$ C(w)=-\\frac{1}{m}\\sum_{i=1}^{m}y^i\\cdot log(h_w(x^i))+(1-y^i)\\cdot log(1-h_w(x^i))+\\frac{\\lambda}{2m}\\sum_{j=1}^nw_j^2 $ \n",
    "\n",
    "A költség függvény deriváltját a gradiens módszerhez az alábbi képlettel számoltuk:\n",
    "\n",
    "$ \\frac{\\partial}{\\partial w_j}C(w)=\\frac{1}{m}\\sum_{i=1}^{m}(h_w(x^i)-y^i)\\cdot x_j^i+\\frac{\\lambda}{m}w_j $ <br>\n",
    ", ahol figyeljünk arra, hogy a BIAS tagot nem büntetjük!\n",
    "\n",
    "Majd pedig a Gradient Descent súlymodosító alapképletével modosítottuk a súlyokat:\n",
    "\n",
    "$w_j:=w_j-\\mu\\frac{\\partial}{\\partial w_j}C(w)$ \n",
    "\n",
    "Ezen három kulcs lépésből épül fel a Gradient Descent algoritmus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Írja meg a költségfüggvényt és gradienseket kiszámoló lrCostFunction() függvényt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))                                                 # szigmoid függvény definíció\n",
    "\n",
    "def lrCostFunction(w,X,Y,Lambda):                                           # logaritmusos költségfüggvény definíció\n",
    "####################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "####################################################################\n",
    "    return C, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_t = np.array([-2,-1,1,2]).reshape(4,1)                                 # teszt eset\n",
    "X_t = np.array([np.linspace(0.1,1.5,15)]).reshape(3,5).T                  \n",
    "X_t = np.hstack((np.ones((5,1)),X_t))                                    \n",
    "Y_t = np.array([1,0,1,0,1]).reshape(5,1)  \n",
    "Lambda = 3\n",
    "\n",
    "C,grad = lrCostFunction(w_t, X_t, Y_t, Lambda)                           # költségfüggvény Lambda = 3\n",
    "print('\\nTest weight: [-2 -1 1 2]\\n''''\n",
    "Testing lrCostFunction() with regularization ... \n",
    "Cost function value: %.6f''' % C, ' (Expected: 2.534819)')\n",
    "print('''\\nExpected gradients:\n",
    " [[0.146561]\n",
    " [-0.548558]\n",
    " [0.724722]\n",
    " [1.398003]]\n",
    "Computed gradients:\\n''',grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Írja meg a gradiens csükkentést végrehajtó gradientDescent() függvényt. Az egyes iterációkban mentse el egy változóba az aktuális költség értéket a lefutás nyomon követése érdekében."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,Y,w,learning_rate,num_iters,Lambda):                          # gradiens módszer definíciója\n",
    "############################################################    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "############################################################    \n",
    "    return w, C_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: One vs All\n",
    "\n",
    "Célunk, hogy az eddig megismert és lekódolt 2 osztályos klasszifikáciüt kibővítsük több osztály szétválasztására is. Ezt megtehetjük egy egyszerű megfontolás mentén. Bármilyen klasszifikációs problémát vezessünk vissza két osztály elkülönítésére és hajtsuk végre ezt az eljárást annyiszor, ahány osztályt meg szeretnénk különböztetni.\n",
    "\n",
    "<img src=\"files/Pics/L05_OneVSAll.png\" width=450>\n",
    "\n",
    "Így gyíkorlatilag a hipotézis függvényünk minden mintához hozzá rendel annyi valószínűséget, ahány osztályunk van. Ennek megfelően a döntésünk az lesz, amelyik osztály a legnagyobb valószínűséget fogja elérni.\n",
    "\n",
    "$h_{w}^{(i)} = P(y=i|_{x,w})$ <br>\n",
    ",ahol a fenti illusztráció szerint $i = 1,2,3$.\n",
    "\n",
    "A számok osztáloyzása során 10 osztáylunk lesz, mivel a számjegyek 0-9 ig terjednek. Amire figyelni kell, hogy az adatbázisban a 0 számjegyek vannak 10-essel jelölve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, Y, num_labels, Lambda):                                     # One vs All definíciója\n",
    "    m, n = X.shape[0],X.shape[1]                                            # \n",
    "    w_init = np.zeros((n + 1, 1))                                           # init súly oszlopvektor, n+1 x 1\n",
    "    w_all = []  \n",
    "    C_all = []\n",
    "\n",
    "#############################################################               # A Bias tagokat ne felejtsük el hozzá adni\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#############################################################    \n",
    "    return w_all, C_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda = 0.1\n",
    "num_labels = 10\n",
    "\n",
    "w_all, C_all = oneVsAll(X,Y,num_labels,Lambda)\n",
    "\n",
    "plt.plot(C_all[0])\n",
    "plt.title(\"Cost function for y = 1 (Digit 1)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"C_all value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Predikció és pontosság\n",
    "\n",
    "Nézzük vissza, hogy a tanított algoritmusunk milyen pontosságot érne el a tanító mintákon. A predikciós lépést most batch módszerrel az összes mintára egyszerre végezzük el. Minden mintára kiszámoljuk az összes osztályba való tartozás valószínűségét, majd a végleges predikciónkhoz kiválasztjuk ezek közül a legnagyobb valószínűséggel rendelkező osztályt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionOneVsAll(w_all,X):\n",
    "    m = X.shape[0]\n",
    "    X = np.hstack((np.ones((m,1)),X))\n",
    "###########################################################\n",
    "                                      \n",
    "    \n",
    "    \n",
    "###########################################################    \n",
    "    return predictions              \n",
    "\n",
    "pred = predictionOneVsAll(w_all, X)\n",
    "acc = sum(pred[:,np.newaxis]==Y)[0]/5000*100\n",
    "print(\"Training Set Accuracy: %.2f\" % acc,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
